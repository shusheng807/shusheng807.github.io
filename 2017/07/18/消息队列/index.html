<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>消息队列 | Hello weixushuai</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Kafka 在流式计算中，Kafka一般是用来缓存数据，Spark、Flink等听过消费kafka的数据进行计算 Apache Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。 Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高吞吐量">
<meta name="keywords" content="消息队列">
<meta property="og:type" content="article">
<meta property="og:title" content="消息队列">
<meta property="og:url" content="http://shusheng807.github.io/2017/07/18/消息队列/index.html">
<meta property="og:site_name" content="Hello weixushuai">
<meta property="og:description" content="Kafka 在流式计算中，Kafka一般是用来缓存数据，Spark、Flink等听过消费kafka的数据进行计算 Apache Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。 Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高吞吐量">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/1563178905703.png">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/1563178993244.png">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/1563179087594.png">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/1563179123406.png">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/1563179448126.png">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/kafka%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.jpg">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/partition%E5%A4%9A%E5%89%AF%E6%9C%AC.jpg">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/offset.jpg">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/offset%E6%B6%88%E8%B4%B9.jpg">
<meta property="og:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/1563189841442.png">
<meta property="og:updated_time" content="2019-07-18T13:29:41.422Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="消息队列">
<meta name="twitter:description" content="Kafka 在流式计算中，Kafka一般是用来缓存数据，Spark、Flink等听过消费kafka的数据进行计算 Apache Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。 Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高吞吐量">
<meta name="twitter:image" content="http://shusheng807.github.io/2017/07/18/消息队列/assets/1563178905703.png">
  
    <link rel="alternate" href="/atom.xml" title="Hello weixushuai" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hello weixushuai</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shusheng807.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-消息队列" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/07/18/消息队列/" class="article-date">
  <time datetime="2017-07-18T13:11:15.000Z" itemprop="datePublished">2017-07-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/kafka/">kafka</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      消息队列
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><ul>
<li>在流式计算中，Kafka一般是用来缓存数据，Spark、Flink等听过消费kafka的数据进行计算</li>
<li>Apache Kafka是一个开源<strong>消息</strong>系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。</li>
<li>Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高吞吐量、低等待的平台。</li>
<li>Kafka是一个分布式消息队列：生产者、消费者的功能。它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现</li>
<li>Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer,消息接受者称为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)称为broker。</li>
<li>无论是kafka集群，还是producer和consumer都依赖于<strong>zookeeper</strong>集群保存一些meta信息，来保证系统可用性</li>
</ul>
<a id="more"></a>

<h3 id="JMS"><a href="#JMS" class="headerlink" title="JMS"></a>JMS</h3><h3 id="为什么需要消息队列"><a href="#为什么需要消息队列" class="headerlink" title="为什么需要消息队列"></a>为什么需要消息队列</h3><ul>
<li>消息系统的核心作用就是三点：解耦、异步和并行</li>
<li>通过用户注册的案例来说明消息系统的作用<ol>
<li>用户注册的一般流程              <img src="assets/1563178905703.png" alt><ul>
<li>问题：随着后端流程越来越多，每步流程都需要额外的耗费很多时间，从而会导致用户更长的等待延迟</li>
</ul>
</li>
<li>用户注册的并行执行                              <img src="assets/1563178993244.png" alt><ul>
<li>问题：系统并行的发起了4个请求，4个请求中，如果某一个环节执行1分钟，其他环节再快，用户也需要等待1分钟。如果其中一个环节异常之后，整个服务挂掉了</li>
<li>时间消耗对比图：                <img src="assets/1563179087594.png" alt></li>
</ul>
</li>
<li>用户注册的最终一致                            <img src="assets/1563179123406.png" alt><ul>
<li>保证<strong>主流程</strong>的正常执行，执行成功之后，发送MQ消息出去</li>
<li>需要这个destination的其他系统通过消费数据再执行，造成最终一致</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="kafka核心组件"><a href="#kafka核心组件" class="headerlink" title="kafka核心组件"></a>kafka核心组件</h3><p><img src="assets/1563179448126.png" alt></p>
<ul>
<li>Topic<ul>
<li>消息根据Topic进行归类</li>
</ul>
</li>
<li>Producer<ul>
<li>发送消息者</li>
</ul>
</li>
<li>Consumer<ul>
<li>消息接收者</li>
</ul>
</li>
<li>broker<ul>
<li>每个kafka实例(server)</li>
</ul>
</li>
<li>ZooKeeper<ul>
<li>依赖集群保存meta信息</li>
</ul>
</li>
</ul>
<h3 id="kafka整体架构"><a href="#kafka整体架构" class="headerlink" title="kafka整体架构"></a>kafka整体架构</h3><p><img src="assets/kafka%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.jpg" alt></p>
<ul>
<li>一个kafka架构包括若干个Producer(服务器日志、业务数据、web前端产生的page view等)、若干个broker(kafka支持水平扩展，一般broker数量越多，集群的吞吐量越大)、若干个consumer group、一个ZooKeeper集群(kafka通过ZooKeeper管理集群配置、选举Leader、当consumer发生变化时进行rebalance)</li>
<li>各个角色：<ul>
<li>Producer<ul>
<li>消息生产者，就是向kafka broker发消息的客户端</li>
</ul>
</li>
<li>Consumer<ul>
<li>消息消费者，就是从kafka broker获取消息的客户端</li>
</ul>
</li>
<li>Topic<ul>
<li>可以理解为一个队列，将消息进行分类</li>
<li>发送到集群的每一条消息都要指定一个topic</li>
</ul>
</li>
<li>Consumer Group<ul>
<li>这是kafka用来实现一个topic消息的广播(发送给所有的consumer)和单播 （发送给任意一个consumer）的手段</li>
<li>一个topic可以有多个CG，topic的消息会复制(概念上的复制)到所有的CG，但每个partition只会把消息发送给CG中的一个consumer，如果要实现广播，只要每个consumer有一个独立的CG即可；要实现单播只要所有的consumer在同一个CG</li>
<li>用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic</li>
</ul>
</li>
<li>broker<ul>
<li>一台kafka服务器节点就是一个broker，一个集群由多个broker组成，一个broker可以容纳多个topic</li>
</ul>
</li>
<li>partition<ul>
<li>为了实现扩展性，一个非常大的topic可以分不到多个broker上，一个topic可以分为多个partition，每个partition是一个<strong>有序</strong>的队列，partition中的每条消息都会被分配一个有序的id(offset)，kafka只保证按一个partition中的顺序将消息发送给consumer，不保证一个topic的整体(多个partition)的顺序</li>
<li>为了提高kafka的吞吐量，一般要设置多个partition</li>
</ul>
</li>
<li>offset<ul>
<li>kafka的存储文件都是按照offset.kafka来命名的，用offset做名字的好处是方便查找</li>
</ul>
</li>
</ul>
</li>
<li>关系解释<ul>
<li>topic 与 partition的关系<ul>
<li>一个topic为一类消息，每条消息必须指定一个topic。物理上，一个topic分成一个或多个partition，每个partition有多个副本分布在不同的broker<img src="assets/partition%E5%A4%9A%E5%89%AF%E6%9C%AC.jpg" alt></li>
<li>每个partition在存储层面是一个append log文件，发布到该partition的消息会追加到log文件的尾部，为顺序写入磁盘(顺序写入磁盘比随机写内存的效率还要高)，每条消息在log文件中的位置成为offset(偏移量)，唯一标记一条消息                  <img src="assets/offset.jpg" alt></li>
<li>每个consumer唯一保存的元数据是offset值，这个位置完全被消费者控制，因此消费者可以采用任何顺序来消费记录<img src="assets/offset%E6%B6%88%E8%B4%B9.jpg" alt></li>
<li>对于传统的消息队列而言，一般会删除已经被消费的消息，而kafka集群会保留所有的消息，但是由于磁盘的限制，不可能永久保留所有消息，因此kafka提供了两种策略删除数据：基于时间(让kafka删除2天或一周的数据)、基于partition文件大小(让kafka在partition文件超过1GB时删除数据)</li>
<li>注意：kafka只能保证partition中记录是有序的，不能保证topic中不同partition之间是有序的</li>
</ul>
</li>
<li>Consumer group 与 consumer<ul>
<li>一个consumer group由一个或多个consumer实例组成，目的是便于扩容与容错</li>
<li>consumer group内所有的consumer协调在一起来消费订阅的topic中所有分区(partition)，即：一个consumer group对应一个topic，也就是说使用一个consumer group的consumer来消费topic中的所有消息</li>
<li>kafka是发布与订阅模式，这个订阅者是consumer group，而不是consumer。<strong>每一条消息只会被统一个consumer group中的一个consumer实例消费，不同的消费者组可以同时消费同一条消息</strong>![](assets/consumer group.jpg)</li>
<li>为了实现传统的消息队列中只被消费一次的语义，kafka保证同一个消费组只有一个消费者会消费一条消息，kafka还允许不同的消费组同时消费一条消息，这一特性可以为消息的多元化处理提供了支持，kafka的设计理念就是同时提供离线处理和实时处理，因此可以使用storm、spark Streaming、Flink这种实时流处理系统对消息进行实时在线处理，同时使用hadoop、spark这种批处理系统进行离线处理，还可以将数据实时备份到另一个数据中心，只需要保证这三个操作的消费者实例在不同的consumer group中即可</li>
</ul>
</li>
</ul>
</li>
<li>Consumer Rebalance<ul>
<li>kafka保证了同一个consumer group中只有一个consumer实例会消费某条消息，实际上，kafka保证的是<strong>稳定状态</strong>下每一个消费者实例只会消费一个或多个特定partition数据，而某个partition的数据只会被某一特定的consumer实例消费，这样设计的劣势是无法让同一个consumer group中的consumer均匀消费的；优势是每个consumer不用跟大量的broker进行通信，减少了通信开销，也降低了分配的难度，并且，同一个partition数据是有序的，保证了有序被消费，根据consumer group中的consumer数量和partition数量，可以分为：<ul>
<li>consumer group中的consumer数量少于partition数量，则至少有1个consumer会消费多个partition数据</li>
<li>consumer group中的consumer数量多于partition数量，则会有部分的consumer无法消费该topic中任何一条消息</li>
<li>consumer group中的consumer数量等于partition数量，则正好一个consumer消费一个partition数据</li>
</ul>
</li>
</ul>
</li>
<li>consumer rebalance的控制策略是：由每个consumer通过ZooKeeper完成的</li>
</ul>
<h3 id="consumer与topic的关系"><a href="#consumer与topic的关系" class="headerlink" title="consumer与topic的关系"></a>consumer与topic的关系</h3><ul>
<li>本质上：kafka只支持topic</li>
<li>每个consumer group中可以有多个consumer，每个consumer属于一个consumer group，通常情况下，一个group中会包含多个consumer，这样不仅可以提高topic中消息的并发消费能力，而且还能提高”故障容错”性，如果consumer group中的某个consumer失效，那么其消费的partition就会由其他的consumer自动接管</li>
<li>对于topic中的一条特定的消息，只会被订阅此topic的每个consumer group中的其中一个consumer消费，此消息不会发送给一个group的多个consumer；一个consumer group中所有的consumer将会交错的消费整个topic，每个group中的consumer消息消费互相独立，可以认为一个group是一个”订阅者”</li>
<li>在kafka中，同一时刻，一个partition中的消息只会被group中的一个consumer消费；一个topic中的每个partition，只会被一个”订阅者”(consumer group)中的一个consumer消费，不过一个consumer可以同时消费多个partition中的消息</li>
<li>kafka的设计原理决定了：对于一个topic，同一个consumer group中不能有对于partition个数的consumer同时消费，否则将意味着某些consumer将无法得到消息</li>
</ul>
<h3 id="kafka消息的分发"><a href="#kafka消息的分发" class="headerlink" title="kafka消息的分发"></a>kafka消息的分发</h3><ul>
<li>Producer客户端负责消息的分发</li>
<li>kafka集群中的任何一个broker都可以向producer提供metadata信息，这些metadata中包含”集群中存活的servers(broker)列表”和”partitions leader列表“信息</li>
<li>当producer获取到metadata信息之后，producer将会和topic下所有的partition leader保持socket连接</li>
<li>消息由producer直接通过socket发送到broker，中间不会经过任何”路由层”，事实上，消息被路由到哪个partition上由producer客户端决定的，比如可以采用“random”、“key-hash”、“轮询”等，如果一个topic中有多个partitions，那么在producer端实现”消息均衡分发”是必要的</li>
<li>producer端的配置文件中，开发者可以指定partition路由的方式</li>
<li>在配置文件中，还可以设置：发送数据是否需要服务端(broker)的反馈<code>request.required.ack=值</code>，其值可以为：<ul>
<li>0：producer不会等待broker发送的ack</li>
<li>1：当leader接收到消息之后发送ack</li>
<li>-1：当所有的follower都同步消息成功后发送ack</li>
</ul>
</li>
</ul>
<h3 id="consumer的负载均衡"><a href="#consumer的负载均衡" class="headerlink" title="consumer的负载均衡"></a>consumer的负载均衡</h3><ul>
<li>当一个consumer group中有consumer加入或者离开时，会触发partitions的负载均衡，负载均衡的最终目的是：提升topic的并发消费能力，步骤如下：<ul>
<li>获取consumer消费的起始分区号</li>
<li>计算出consumer消费的分区数</li>
<li>用起始分区好的哈希值模上分区数的结果</li>
</ul>
</li>
</ul>
<h3 id="segment"><a href="#segment" class="headerlink" title="segment"></a>segment</h3><ul>
<li><p>一个分区被分成了多个相同大小的segment(默认大小为1G)</p>
<ul>
<li><p>segment file由两部分组成：分别为index file和data file，这两个文件一一对应，成对出现，后缀为<code>.index</code>和<code>.log</code>分别表示segment的索引文件、数据文件</p>
</li>
<li><p>segment文件命名规则：partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。该数值最大为64位long大小，19位数字字符长度，长度不够用0来填充</p>
</li>
<li><p>index文件中存储大量的元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址</p>
</li>
<li><p>data文件由许多message组成，其物理结构图为<img src="assets/1563189841442.png" alt></p>
<table>
<thead>
<tr>
<th>关键字</th>
<th>解释说明</th>
</tr>
</thead>
<tbody><tr>
<td>8 byte offset</td>
<td>在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message</td>
</tr>
<tr>
<td>4 byte message size</td>
<td>message大小</td>
</tr>
<tr>
<td>4 byte CRC32</td>
<td>用crc32校验message</td>
</tr>
<tr>
<td>1 byte “magic”</td>
<td>表示本次发布Kafka服务程序协议版本号</td>
</tr>
<tr>
<td>1 byte “attributes”</td>
<td>表示为独立版本、或标识压缩类型、或编码类型。</td>
</tr>
<tr>
<td>4 byte key length</td>
<td>表示key的长度,当key为-1时，K byte key字段不填</td>
</tr>
<tr>
<td>K byte key</td>
<td></td>
</tr>
<tr>
<td>value bytes payload</td>
<td>表示实际消息数据</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<h3 id="kafka的存储机制"><a href="#kafka的存储机制" class="headerlink" title="kafka的存储机制"></a>kafka的存储机制</h3><ol>
<li>broker首先接收到数据，然后将数据放到操作系统(Linux)的缓存里(pagecache)，每个pagecache会尽可能多的使用空闲内存，会有sendfile技术尽可能多的减少操作系统和应用程序之间的重复缓存</li>
<li>写入数据的时候使用顺序写入，速速可达600M/s</li>
<li>如果此时正好有消费者消费数据，会直接绕过磁盘直接从pagecache中进行消费</li>
</ol>
<ul>
<li>在kafka文件存储中，同一个topic下有多个不同的partition，每个partition为一个分区，partition命名规则为<code>topic名称 + 有序序号</code></li>
</ul>
<h3 id="数据的分发策略"><a href="#数据的分发策略" class="headerlink" title="数据的分发策略"></a>数据的分发策略</h3><ul>
<li>kafka默认会调用自己的分区器(DefaultPartitioner)，也可以自定义分区器(不过需要自定义实现Partitioner特质)</li>
</ul>
<h3 id="保证kafka数据不丢失"><a href="#保证kafka数据不丢失" class="headerlink" title="保证kafka数据不丢失"></a>保证kafka数据不丢失</h3><ul>
<li>创建topic的时候，需要指定副本数和分区数，多副本机制保证了数据的安全性</li>
<li>kafka存储数据的生存周期默认是168小时(7天)，可以根据需求进行调整</li>
</ul>
<h3 id="kafka-选举机制"><a href="#kafka-选举机制" class="headerlink" title="kafka 选举机制"></a>kafka 选举机制</h3><ul>
<li>kafka在所有的broker中选出一个controller，所有partition的leader选举都由该controller决定，controller会将Leader的改变直接通过RPC的方式(该方式比ZooKeeper queue的方式更高效)通知需要为此做出相应的broker。同时，controller也负责增删topic以及Replica的重新分配</li>
<li>当有broker发生失败迁移时，controller的处理过程：<ul>
<li>Controller在ZooKeeper注册watch，一旦有broker宕机(这是用宕机代表任何让系统认为其挂掉的情况，包括但不限于机器断电，网络不可用，GC导致的Stop The World，进程crash等)，其在ZooKeeper对应的ZNode会自动被删除，ZooKeeper会</li>
</ul>
</li>
</ul>
<h3 id="kafka集群搭建"><a href="#kafka集群搭建" class="headerlink" title="kafka集群搭建"></a>kafka集群搭建</h3><ul>
<li><p>解压安装包</p>
</li>
<li><p>配置环境变量</p>
</li>
<li><p>修改配置文件</p>
<ul>
<li><p>producer.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.servers=hadoop1:9092,hadoop2:9092,hadoop3:9092</span><br></pre></td></tr></table></figure>
</li>
<li><p>server.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">broker.id=n</span><br><span class="line">log.dirs=$kafka/data</span><br><span class="line">zookeeper.connect=hadoop1:2181,hadoop2:2181,hadoop3:2181</span><br></pre></td></tr></table></figure>
</li>
<li><p>consumer.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop1:9092,hadoop2:9092,hadoop3:9092</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>分发目录</p>
</li>
<li><p>修改其他节点上<code>server.properties</code>文件中的<code>broker.id</code>的值</p>
</li>
</ul>
<h3 id="kafka常用命令"><a href="#kafka常用命令" class="headerlink" title="kafka常用命令"></a>kafka常用命令</h3><ul>
<li><p>启动kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/kafka-server-start/sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看当前kafka中的topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeper hadoop1:2181  # ZooKeeper为集群中的任一节点</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper hadoop1:2181 --replication-factor --partitions 1 --topic topic名字</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --delete --zookeeper hadoop1:2181 --topic second-topic</span><br></pre></td></tr></table></figure>

<ul>
<li>注意：使用删除topic，需要在<code>server.properties</code>文件中设置<code>delete.topic.enable=true</code>否则只是标记删除或者直接重启kafka</li>
</ul>
</li>
<li><p>通过shell命令发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic first-topic</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过shell命令消费消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --zookeeper hadoop1:2181 --from-beginning --topic first-topic</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看消费位置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>
</li>
<li><p>查看某个topic的详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --topic first-topic --describe --zookeeper hadoop1:2181</span><br></pre></td></tr></table></figure>
</li>
<li><p>对分区数进行修改</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper hadoop1:2181 --alter --partitions 15 --topic first-topic</span><br></pre></td></tr></table></figure>

</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shusheng807.github.io/2017/07/18/消息队列/" data-id="cjy9k7flr000i7svuqsywniql" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/消息队列/">消息队列</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/07/19/shuffle/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          shuffle
        
      </div>
    </a>
  
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/JVM/">JVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习笔记/">学习笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/消息队列/">消息队列</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/JVM/" style="font-size: 10px;">JVM</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/学习笔记/" style="font-size: 10px;">学习笔记</a> <a href="/tags/消息队列/" style="font-size: 10px;">消息队列</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/07/19/《图解Spark-核心技术与案例实战》学习笔记_day01/">《图解Spark-核心技术与案例实战》学习笔记——day01</a>
          </li>
        
          <li>
            <a href="/2019/07/19/JVM/">JVM</a>
          </li>
        
          <li>
            <a href="/2019/07/15/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/07/19/shuffle/">shuffle</a>
          </li>
        
          <li>
            <a href="/2017/07/18/消息队列/">消息队列</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 韦徐帅<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>